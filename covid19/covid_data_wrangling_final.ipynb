{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbc7c2bd-4a52-4cdb-8551-2a9e136908c2",
   "metadata": {},
   "source": [
    "# 1 Covid-19 Data Collection and Wrangling<a id='1_data_collection_wrangling'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac9088f-8b35-410e-8db8-c4ce9a6d18c7",
   "metadata": {},
   "source": [
    "## 1.1 Contents<a id='1.1_contents'></a>\n",
    "* [1 Covid-19 Data Collection and Wrangling](#1_data_collection_wrangling)\n",
    "  * [1.1 Contents](#1.1_contents)  \n",
    "  * [1.2 Imports](#1.2_imports)\n",
    "  * [1.3 Functions](#1.3_functions)\n",
    "      * [1.3.1 Function: add_vaccination](#1.3.1_add_vaccination)\n",
    "      * [1.3.2 Function: add_case](#1.3.2_add_case)\n",
    "      * [1.3.3 Function: add_weather](#1.3.3_add_weather)\n",
    "      * [1.3.4 Function: country_name_to_iso2](#1.3.4_country_name_to_iso2)\n",
    "      * [1.3.5 Function: add holiday](#1.3.5_add_holiday)\n",
    "      * [1.3.6 Function: vac_iso_code_to_alpha2](#1.3.6_vac_iso_code_to_alpha2)\n",
    "      * [1.3.7 Function: case_name_to_alpha2](#1.3.7_case_name_to_alpha2) \n",
    "  * [1.4 Load data](#1.4_load_data)\n",
    "  * [1.5 Preprocess mobility data](#1.5_preprocess_mobility_data)\n",
    "  * [1.6 Merge data](#1.6_merge_data)\n",
    "  * [1.7 Save data](#1.7_save_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98c8305-f371-4cbf-9a85-ef4dc9df9f52",
   "metadata": {},
   "source": [
    "## 1.2 Imports<a id='1.2_imports'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "970472e3-316b-43c9-a7d1-4d81a6d72368",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from deepdiff import DeepDiff\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as holidayCalendar\n",
    "from wwo_hist import retrieve_hist_data\n",
    "import pycountry\n",
    "import holidays\n",
    "from countryinfo import CountryInfo\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cf0ff1-91fa-4cc3-97a2-506d0a8e2f24",
   "metadata": {},
   "source": [
    "## 1.3 Functions<a id='1.3_functions'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c3e508-8a3c-4b9b-b5ac-6304453d5c33",
   "metadata": {},
   "source": [
    "#### 1.3.1 Functions: add_vaccination <a id='1.3.1_add_vaccination'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e668b72a-dec4-4acf-9772-8c5b5bb0f4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_vaccination(df_place, df_vac, country_code):\n",
    "    # join the vaccination data\n",
    "    df_place_vac = df_vac.loc[df_vac[\"iso_code\"]==country_code,[\"date\",\"people_vaccinated_per_hundred\"]]\n",
    "    df_place_vac.rename(columns = {\"people_vaccinated_per_hundred\": \"vac\"}, inplace=True)\n",
    "    df_place_vac[\"date\"] = pd.to_datetime(df_place_vac.date) # convert the index to datetime64\n",
    "    df_place_vac.set_index(\"date\", drop=True ,inplace=True)\n",
    "    df_place = df_place.merge(df_place_vac, on=\"date\", how=\"left\")\n",
    "    # fill in missing values for vaccination\n",
    "    if np.isnan(df_place[\"vac\"][0]): # if the initial value is NaN, put 0\n",
    "        df_place.loc[df_place.index[0],\"vac\"]=0\n",
    "        df_place.loc[:,\"vac\"] = df_place[\"vac\"].fillna(method='ffill') # must assign the filled list to the \"vac\" column\n",
    "    return df_place"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9cc1f0-d4eb-4573-bc39-5374b8aca128",
   "metadata": {},
   "source": [
    "#### 1.3.2 Functions: add_case <a id='1.3.2_add_case'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5356d5b-e727-4cdf-99ee-ee56427c1962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_case(df_place, df_case, country_code):\n",
    "    # join the case data\n",
    "    df_place_case = df_case.loc[:,[\"date\", country_code]].set_index(\"date\") \n",
    "    df_place_case.index = pd.to_datetime(df_place_case.index)\n",
    "    df_place_case.rename(columns = {country_code:\"case_mil\"}, inplace=True)\n",
    "    df_place = df_place.merge(df_place_case, on=\"date\", how=\"left\")\n",
    "    # fill in missing values for case\n",
    "    if np.isnan(df_place[\"case_mil\"][0]): # if the initial value is NaN, put 0\n",
    "        df_place.loc[df_place.index[0],\"case_mil\"]=0\n",
    "        df_place.loc[:,\"case_mil\"] = df_place[\"case_mil\"].fillna(method='ffill') # must assign the filled list to the \"vac\" column\n",
    "    return df_place"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc310cc-32aa-4c74-afc8-a40cd96070b5",
   "metadata": {},
   "source": [
    "#### 1.3.3 Functions: add_weather <a id='1.3.3_add_weather'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0c854157-ea34-4b45-92c9-214504a3682c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_weather(df_place):\n",
    "    # normalize\n",
    "    api_key = '619972ecb8e64a2ca8b152638212709' # note that this key expires on 11/21/21\n",
    "    country_code = df_place.country_region_code.unique()[0]\n",
    "    country = CountryInfo(country_code)\n",
    "    capital = country.capital().replace(\" \", \"_\") \n",
    "    capital = capital.replace(\".\",\"\")\n",
    "    start_date = df_place.index[0].strftime('%d-%b-%Y') \n",
    "    end_date = df_place.index[-1].strftime('%d-%b-%Y')\n",
    "    frequency=24\n",
    "    try: \n",
    "        hist_weather = retrieve_hist_data(api_key, [capital], start_date, end_date,\n",
    "                                      frequency, location_label = False, export_csv = False, store_df = True);\n",
    "        df_weather = hist_weather[0][[\"date_time\", \"cloudcover\", \"tempC\", \"humidity\", \"precipMM\"]] \n",
    "        df_weather.insert(len(df_weather.columns), \"date\", pd.to_datetime(df_weather[\"date_time\"]))\n",
    "        df_weather.drop([\"date_time\"], axis=1, inplace=True)\n",
    "        df_weather.set_index([\"date\"], inplace=True)\n",
    "        df_place = df_place.join(df_weather, on=\"date\", how=\"left\")\n",
    "    except: \n",
    "        print(\"No match found!\")\n",
    "    return df_place"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b8f5ec-8552-441f-868d-42d53700b068",
   "metadata": {},
   "source": [
    "#### 1.3.4 Functions: country_name_to_iso2 <a id='1.3.4_country_name_to_iso2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f366edf2-22d7-428c-83ad-629b37c78d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def country_name_to_iso2(holiday_dict):\n",
    "    holiday_country_code_dict = {}\n",
    "    countries = holiday_dict.keys()\n",
    "    for country in countries:\n",
    "        try:\n",
    "            country_code = CountryInfo(country).iso()['alpha2']\n",
    "            holiday_country_code_dict.update({country_code:holiday_dict[country]})\n",
    "        except KeyError as e:\n",
    "            print('I got a KeyError - reason %s' % str(e))      \n",
    "    return holiday_country_code_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb49d73d-7f50-4c04-8802-c4779418d6ff",
   "metadata": {},
   "source": [
    "#### 1.3.5 Functions: add_holiday <a id='1.3.5_add_holiday'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25a25cef-a826-4aa3-92d0-0db712c438f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_holiday(df_place, holid_country_code): \n",
    "    country_code = df_place.country_region_code.unique()[0]\n",
    "    holiday_timestamps = holid_country_code[country_code]\n",
    "    df_holiday = pd.DataFrame({'date': holiday_timestamps, 'holiday':[1 for timestamp in holiday_timestamps]})\n",
    "    df_holiday.set_index(['date'], inplace=True)\n",
    "    df_place = df_place.join(df_holiday, how='left', on='date')\n",
    "    df_place['holiday'].fillna(value=0, inplace=True)\n",
    "    df_place['holiday'] = [int(element) for element in list(df_place['holiday'])]\n",
    "    return df_place"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e666dc3c-133c-478a-801f-9587ddf24415",
   "metadata": {},
   "source": [
    "#### 1.3.6 Functions: vac_iso_code_to_alpha2 <a id='1.3.6_vac_iso_code_to_alpha2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40a78377-35e6-4774-a31a-dc4aa08aa714",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vac_iso_code_to_alpha2(df_vac):\n",
    "    alpha2 = []  \n",
    "    for iso3 in list(df_vac.iso_code):\n",
    "        try: \n",
    "            alpha2.append(pycountry.countries.get(alpha_3=iso3).alpha_2)\n",
    "        except: \n",
    "            alpha2.append(\"\")\n",
    "    df_vac['iso_code'] = alpha2\n",
    "    return df_vac "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc6b00a-7016-4508-9614-548d695206fc",
   "metadata": {},
   "source": [
    "#### 1.3.7 Functions: case_name_to_alpha2 <a id='1.3.7_case_name_to_alpha2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e19816a-25bb-40b8-b68f-e475c8492d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def case_name_to_alpha2(df_case): \n",
    "    for country in df_case.columns:\n",
    "        country_obj = pycountry.countries.get(name = country)\n",
    "        try: \n",
    "            df_case.rename(columns={country:country_obj.alpha_2}, inplace=True)\n",
    "        except: \n",
    "            if country == 'South Korea':\n",
    "                df_case.rename(columns={country:'KR'}, inplace=True)  \n",
    "            elif country == 'Russia':\n",
    "                df_case.rename(columns={country:'RU'}, inplace=True)  \n",
    "    return df_case    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4565b78a-d504-4e3e-bf86-e8a56c75aaa0",
   "metadata": {},
   "source": [
    "## 1.4 Load data - mobility, case, vaccination, holiday <a id='1.4_load_data'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70e09a13-9549-48e8-b97e-b7b8d0322410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I got a KeyError - reason 'christian holidays'\n",
      "I got a KeyError - reason 'jewish holidays'\n",
      "I got a KeyError - reason 'muslim holidays'\n",
      "I got a KeyError - reason 'orthodox holidays'\n",
      "I got a KeyError - reason 'andorra'\n",
      "I got a KeyError - reason 'bahamas'\n",
      "I got a KeyError - reason 'british virgin islands'\n",
      "I got a KeyError - reason 'brunei darussalam'\n",
      "I got a KeyError - reason 'congo'\n",
      "I got a KeyError - reason \"côte d'ivoire\"\n",
      "I got a KeyError - reason 'curaçao'\n",
      "I got a KeyError - reason 'czechia'\n",
      "I got a KeyError - reason 'falkland islands (malvinas)'\n",
      "I got a KeyError - reason 'gambia'\n",
      "I got a KeyError - reason 'holy see (vatican city state)'\n",
      "I got a KeyError - reason 'macao'\n",
      "I got a KeyError - reason 'montenegro'\n",
      "I got a KeyError - reason 'myanmar'\n",
      "I got a KeyError - reason 'saint barthélemy'\n",
      "I got a KeyError - reason 'saint martin (french part)'\n",
      "I got a KeyError - reason 'sao tome and principe'\n",
      "I got a KeyError - reason 'sint maarten (dutch part)'\n",
      "I got a KeyError - reason 'the democratic republic of the congo'\n",
      "I got a KeyError - reason 'the former yugoslav republic of macedonia'\n",
      "I got a KeyError - reason 'timor-leste'\n",
      "I got a KeyError - reason 'turks and caicos islands'\n",
      "I got a KeyError - reason 'u.s. virgin islands'\n"
     ]
    }
   ],
   "source": [
    "# load mobility data (https://www.google.com/covid19/mobility/)\n",
    "df_mob = pd.read_csv('/Users/parkj/Documents/pyDat/dataSet/COVID19_community_mobility_reports/Global_Mobility_Report_asof092221.csv', low_memory=False)\n",
    "# load new cases data (git local repo: /Users/parkj/Documents/pyDat/dataSet/covid-19-data/, repo: https://github.com/owid/covid-19-data)\n",
    "df_case = pd.read_csv('/Users/parkj/Documents/pyDat/dataSet/covid-19-data/public/data/jhu/new_cases_per_million.csv', low_memory=False)\n",
    "df_case = case_name_to_alpha2(df_case)\n",
    "# load vaccination data (git local repo: /Users/parkj/Documents/pyDat/dataSet/covid-19-data/, repo: https://github.com/owid/covid-19-data)\n",
    "df_vac = pd.read_csv('/Users/parkj/Documents/pyDat/dataSet/covid-19-data/public/data/vaccinations/vaccinations.csv', low_memory=False)\n",
    "df_vac = vac_iso_code_to_alpha2(df_vac)\n",
    "# load holiday data\n",
    "with open('/Users/parkj/Documents/pyDat/google_calendar_api_holidays/holidays.pickle', 'rb') as f:\n",
    "    holid = pickle.load(f)\n",
    "holid_code = country_name_to_iso2(holid)\n",
    "holid_code_list = list(holid_code.keys())\n",
    "# set country of interest\n",
    "countries_of_interest = ['AR', 'AU', 'AT', 'BE', 'BR', \\\n",
    "                         'CA', 'DK', 'FI', 'FR', 'DE', \\\n",
    "                         'IN', 'ID', 'IE', 'IL', \\\n",
    "                         'IT', 'JP', 'KR', 'MX', 'NL', \\\n",
    "                         'NO', 'RU', 'SA', 'SG', 'ES', \\\n",
    "                         'SE', 'CH', 'GB', 'US']   \n",
    "# Argentina, Australia, Austria, Belgium, Brazil\n",
    "# Canada, Denmark, Finland, France, Germany   \n",
    "# India, Indonesia, Ireland, Israel\n",
    "# Italy, Japan, Korea, Mexico, Netherlands \n",
    "# Norway, Russia, Saudi Arabia, Singapore, Spain\n",
    "# Sweden, Switzerland, UK, US    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad523dc-f4cb-4d6f-a31b-a526437a3499",
   "metadata": {},
   "source": [
    "#### Load Mobility, Vaccination, and Case Data\n",
    "##### Google Mobility Data\n",
    "Changes for each day are compared to a ***baseline*** value for that day of the week:\n",
    "1. The baseline is the median value, *for the corresponding day of the week*, during the 5-week period Jan 3–Feb 6, 2020.\n",
    "2. The datasets show trends over several months with the most recent data representing approximately 2-3 days ago—this is how long it takes to produce the datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbe48ba-008b-4e23-bad1-80e69c208b3d",
   "metadata": {},
   "source": [
    "## 1.5 Preprocess mobility data<a id='1.5_preprocess_mobility_data'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fd8714d-8112-4843-bc7d-3e946486ee19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the mobility time series column names\n",
    "df_mob = df_mob.rename(columns = {'retail_and_recreation_percent_change_from_baseline': 'rtrc', \n",
    "                                  'grocery_and_pharmacy_percent_change_from_baseline': 'grph',\n",
    "                                  'parks_percent_change_from_baseline': 'prks',\n",
    "                                  'transit_stations_percent_change_from_baseline': 'tran', \n",
    "                                  'workplaces_percent_change_from_baseline': 'work',\n",
    "                                  'residential_percent_change_from_baseline': 'resi'}, inplace = False)\n",
    "df_mob.date = pd.to_datetime(df_mob.date)\n",
    "df_mob.set_index(\"date\", drop=True ,inplace=True)\n",
    "df_mob.drop(['sub_region_1','sub_region_2','metro_area','iso_3166_2_code','census_fips_code'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d18fa3-426c-4965-806e-9b1a06aee104",
   "metadata": {},
   "source": [
    "## 1.6 Merge data - mobility, vaccination, case, weather, holiday<a id='1.6_merge_data'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "37d772f4-99a7-4b85-9be7-00c247ac10db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# organize data in Global Mobility Report \n",
    "places_id = df_mob.place_id.unique() # unique place ids\n",
    "grouped = df_mob.groupby(df_mob.place_id)\n",
    "dict_country = {} # country dict to contain the national-level data (ignore local regions)\n",
    "country_label = defaultdict(list)\n",
    "\n",
    "for place in places_id:\n",
    "    if pd.isna(place)==False:\n",
    "        df_place = grouped.get_group(place)\n",
    "        country_id = df_place[\"country_region\"].unique()[0] \n",
    "        country_code = df_place[\"country_region_code\"].unique()[0] \n",
    "        if (country_code in countries_of_interest and\n",
    "            country_code in set(df_vac[\"iso_code\"]) and \n",
    "            country_code in set(df_case.columns) and\n",
    "            country_code in holid_code_list and\n",
    "            country_id not in country_label.keys()): # 1st occurrence of country contains national data\n",
    "            # vaccination data\n",
    "            #if country_id in set(df_vac[\"location\"]):\n",
    "            df_place = add_vaccination(df_place, df_vac, country_id)\n",
    "            # case (per million) data   \n",
    "            #if country_id in set(df_case.columns):\n",
    "            df_place = add_case(df_place, df_case, country_code)\n",
    "            # weather data\n",
    "            df_place = add_weather(df_place)\n",
    "            # regional holiday data\n",
    "            df_place = add_holiday(df_place, holid_code)\n",
    "            #if country_id not in country_label.keys(): # 1st occurrence of country contains national data\n",
    "            df_place['dayow'] = df_place.index.weekday # get day of the week (note that 0 corresponds to Monday)\n",
    "            df_place['vac_percMax'] = df_place[\"vac\"]/max(df_place['vac'])*100 # normalize the vaccinated per hundred data\n",
    "            df_place['case_mil_percMax'] = df_place['case_mil']/max(df_place['case_mil'])*100 # normalize the case per million data  \n",
    "            dict_country.update({country_code : df_place}) # the value of country_id is the nested dict mob_thisPlace\n",
    "            country_label[country_id] = 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47a62cf-dcbc-46a2-b382-9003d38fc731",
   "metadata": {},
   "source": [
    "## 1.7 Save data<a id='1.7_Save_data'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0ad9643d-0179-4f58-920e-4eb2c5cd0706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data as pickle - a dictionary (dict_country)\n",
    "filePath_pickle = Path('/Users/parkj/Documents/pyDat/dataSet/covid_country_data.pickle')\n",
    "with open(filePath_pickle, 'wb') as f:\n",
    "    pickle.dump(dict_country, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cd785a0d-5bfb-4eca-a882-aedb881a0623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the saved dictionary from pickle file\n",
    "#filePath_pickle = Path('/Users/parkj/Documents/pyDat/dataSet/covid_country_data.pickle')\n",
    "#with open(filePath_pickle, 'rb') as f:\n",
    "#    dict_country = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
