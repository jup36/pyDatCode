{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c67e4b82-4462-4186-adf3-7f2e64a20f09",
   "metadata": {
    "tags": []
   },
   "source": [
    "### To do list\n",
    "* Update np notations (np.split, np.array)\n",
    "* Write a function to use MAE instead of MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1c5eac-ca09-42d5-85a8-c6da3733eac8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1 Time Series 7-Day Forecasting with LSTM<a id='1_Time_Series_7-Day_Forecasting_with_LSTM'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbffa11-2711-4e5a-a57d-ffbed28f1a6c",
   "metadata": {},
   "source": [
    "## 1.1 Contents<a id='1.1_Contents'></a>\n",
    "* [1 Time Series 7-Day Forecasting with LSTM](#1_Time_Series_7-Day_Forecasting_with_LSTM)\n",
    "    * [1.1 Contents](#1.1_Contents)\n",
    "    * [1.2 Import](#1.2_Import)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b16284-a084-4306-80c2-cbfc84a7cbaa",
   "metadata": {},
   "source": [
    "## 1.2 Import<a id='1.2_Import'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6f0fb281-f561-474c-b3d0-3497895ae009",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import graphviz\n",
    "import pydot_ng as pydot\n",
    "from deepdiff import DeepDiff\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.tree import export_graphviz\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "from keras_visualizer import visualizer \n",
    "from keras import layers \n",
    "#from keras_visualizer import visualizer\n",
    "from keras.utils.vis_utils import plot_model\n",
    "#keras.utils.vis_utils.pydot = pydot\n",
    "%matplotlib inline\n",
    "\n",
    "# Set Matplotlib defaults\n",
    "plt.style.use(\"seaborn-whitegrid\")\n",
    "plt.rc(\"figure\", autolayout=True, figsize=(11, 5))\n",
    "plt.rc(\n",
    "    \"axes\",\n",
    "    labelweight=\"bold\",\n",
    "    labelsize=14,\n",
    "    titleweight=\"bold\",\n",
    "    titlesize=16,\n",
    "    titlepad=10,\n",
    ")\n",
    "plot_params = dict(\n",
    "    color=\"0.75\",\n",
    "    style=\".-\",\n",
    "    markeredgecolor=\"0.25\",\n",
    "    markerfacecolor=\"0.25\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7508bf70-1c7b-4196-a327-b05dbd30288b",
   "metadata": {},
   "source": [
    "#### Split dataset to train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b12ca01-27fd-4ef6-81f5-d5a87ac5b4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(data, n_test):\n",
    "\t# split into standard weeks\n",
    "\ttrain, test = data[:-n_test,:], data[-n_test:,:]\n",
    "\t# restructure into windows of weekly data\n",
    "\ttrain = np.array(np.split(train, len(train)/7))\n",
    "\ttest = np.array(np.split(test, len(test)/7))\n",
    "\treturn train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80594e99-dd3b-47f7-8923-436500bd4716",
   "metadata": {},
   "source": [
    "#### Evaluate one or more weekly forecasts against expected values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35c5a799-baac-4a82-aa8c-6f639dbf9a7e",
   "metadata": {
    "id": "EbQjh7cVjlP_"
   },
   "outputs": [],
   "source": [
    "def evaluate_forecasts(actual, predicted):\n",
    "\tscores = list()\n",
    "\t# calculate an RMSE score for each day\n",
    "\tfor i in range(actual.shape[1]):\n",
    "\t\t# calculate mse\n",
    "\t\tmse = mean_squared_error(actual[:, i], predicted[:, i])\n",
    "\t\t# calculate rmse\n",
    "\t\trmse = sqrt(mse)\n",
    "\t\t# store\n",
    "\t\tscores.append(rmse)\n",
    "\t# calculate overall RMSE\n",
    "\ts = 0\n",
    "\tfor row in range(actual.shape[0]):\n",
    "\t\tfor col in range(actual.shape[1]):\n",
    "\t\t\ts += (actual[row, col] - predicted[row, col])**2\n",
    "\tscore = sqrt(s / (actual.shape[0] * actual.shape[1]))\n",
    "\treturn score, scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fd002c-9b60-4ee8-8a67-cef795807d56",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Summarize scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28785701-af77-4d2d-87f0-5c5442da3f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_scores(name, score, scores):\n",
    "\ts_scores = ', '.join(['%.1f' % s for s in scores])\n",
    "\tprint('%s: [%.3f] %s' % (name, score, s_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e2e596-c4d7-42e2-b418-e265ca396d25",
   "metadata": {
    "id": "yGDcUkPAkHCJ",
    "tags": []
   },
   "source": [
    "#### Convert history into inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc099c10-d8b9-45a2-ae58-53b78452628e",
   "metadata": {
    "id": "IXcCZajCjtpW"
   },
   "outputs": [],
   "source": [
    "def to_supervised(train, n_input, n_out=7):\n",
    "\t# flatten data\n",
    "\tdata = train.reshape((train.shape[0]*train.shape[1], train.shape[2]))\n",
    "\tX, y = list(), list()\n",
    "\tin_start = 0\n",
    "\t# step over the entire history one time step at a time\n",
    "\tfor _ in range(len(data)):\n",
    "\t\t# define the end of the input sequence\n",
    "\t\tin_end = in_start + n_input\n",
    "\t\tout_end = in_end + n_out\n",
    "\t\t# ensure we have enough data for this instance\n",
    "\t\tif out_end <= len(data):\n",
    "\t\t\tX.append(data[in_start:in_end, :]) # note ':' instead of '0' to include all the inputs\n",
    "\t\t\ty.append(data[in_end:out_end, 0])\n",
    "\t\t# move along one time step\n",
    "\t\tin_start += 1\n",
    "\treturn np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17adda3-9be0-429d-aee2-d29a648f642f",
   "metadata": {
    "id": "hiRn5KgGkO2G"
   },
   "source": [
    "#### Build/Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6198416-5442-4812-b569-f018fee9ce9d",
   "metadata": {
    "id": "M3LwslbQjw_z"
   },
   "outputs": [],
   "source": [
    "def build_model(train, n_input, n_out=7):\n",
    "    # prepare data\n",
    "    train_x, train_y = to_supervised(train, n_input, n_out=7)\n",
    "    # define parameters\n",
    "    verbose, epochs, batch_size = 0, 50, 16\n",
    "    n_timesteps, n_features, n_outputs = train_x.shape[1], train_x.shape[2], train_y.shape[1]\n",
    "    # reshape output into [samples, timesteps, features]\n",
    "    train_y = train_y.reshape((train_y.shape[0], train_y.shape[1], 1))\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(200, activation='relu', input_shape=(n_timesteps, n_features)))\n",
    "    model.add(RepeatVector(n_outputs))\n",
    "    model.add(LSTM(200, activation='relu', return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(100, activation='relu')))\n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    visualizer(model, format='png', view=True)\n",
    "    # fit network\n",
    "    model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7390f3-fb0e-42ff-a67e-6f1ffdf5db06",
   "metadata": {
    "id": "FD7UmLTXkpQF"
   },
   "source": [
    "#### Make a forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e56232f-9e89-47fe-8ef7-dccfc3619f32",
   "metadata": {
    "id": "ySJr0Tb5ken9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def forecast(model, history, n_input):\n",
    "\t# flatten data\n",
    "\tdata = array(history)\n",
    "\tdata = data.reshape((data.shape[0]*data.shape[1], data.shape[2]))\n",
    "\t# retrieve last observations for input data\n",
    "\tinput_x = data[-n_input:, :]\n",
    "\t# reshape into [1, n_input, n]\n",
    "\tinput_x = input_x.reshape((1, input_x.shape[0], input_x.shape[1]))\n",
    "\t# forecast the next week\n",
    "\tyhat = model.predict(input_x, verbose=0)\n",
    "\t# we only want the vector forecast\n",
    "\tyhat = yhat[0]\n",
    "\treturn yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c2468b-8249-4fef-9a48-bb34ff3e6db4",
   "metadata": {
    "id": "3M4FddCckzTL"
   },
   "source": [
    "#### Evaluate a single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "104d51ba-1675-41c7-8ac1-8647f9300c95",
   "metadata": {
    "id": "lsLHHsRhkxO6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model(train, test, n_input, n_out=7):\n",
    "\t# fit model\n",
    "\tmodel = build_model(train, n_input, n_out=7)\n",
    "\t# history is a list of weekly data\n",
    "\thistory = [x for x in train]\n",
    "\t# walk-forward validation over each week\n",
    "\tpredictions = list()\n",
    "\tfor i in range(len(test)):\n",
    "\t\t# predict the week\n",
    "\t\tyhat_sequence = forecast(model, history, n_input)\n",
    "\t\t# store the predictions\n",
    "\t\tpredictions.append(yhat_sequence)\n",
    "\t\t# get real observation and add to history for predicting the next week\n",
    "\t\thistory.append(test[i, :])\n",
    "\t# evaluate predictions days for each week\n",
    "\tpredictions = array(predictions)\n",
    "\tscore, scores = evaluate_forecasts(test[:, :, 0], predictions)\n",
    "\treturn score, scores, predictions, test[:, :, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca22974-642c-4b5c-b935-9a6f17fbb351",
   "metadata": {},
   "source": [
    "#### Load and slice the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fad3e685-244d-4b55-87cd-f478b1ec712f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load the saved dictionary from pickle file\n",
    "filePath_pickle = Path('/Users/parkj/Documents/pyDat/dataSet/covid_countryData.pickle')\n",
    "pickle_in = open(filePath_pickle, 'rb')\n",
    "country_dict = pickle.load(pickle_in)\n",
    "# Select US national data\n",
    "df = country_dict['United States']\n",
    "# Slicing data from first Monday to last Sunday\n",
    "df = df[min(df.index[df['dayow']==0]):max(df.index[df['dayow']==6])] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1a510129-64d0-4c48-8479-8905abd1cd1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_mil_percMax</th>\n",
       "      <th>rtrc</th>\n",
       "      <th>grph</th>\n",
       "      <th>prks</th>\n",
       "      <th>tran</th>\n",
       "      <th>work</th>\n",
       "      <th>resi</th>\n",
       "      <th>vac</th>\n",
       "      <th>dayow</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-17</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-18</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-19</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-20</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-21</th>\n",
       "      <td>0.000661</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-02</th>\n",
       "      <td>5.628968</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>50.45</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-03</th>\n",
       "      <td>6.348232</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>50.56</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-04</th>\n",
       "      <td>5.611342</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>50.75</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-05</th>\n",
       "      <td>4.628894</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.91</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-06</th>\n",
       "      <td>1.795572</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.08</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>476 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            case_mil_percMax  rtrc  grph  prks  tran  work  resi    vac  dayow\n",
       "date                                                                          \n",
       "2020-02-17          0.000000   6.0   0.0  28.0  -9.0 -24.0   5.0   0.00      0\n",
       "2020-02-18          0.000000   0.0  -1.0   6.0   1.0   0.0   1.0   0.00      1\n",
       "2020-02-19          0.000000   2.0   0.0   8.0   1.0   1.0   0.0   0.00      2\n",
       "2020-02-20          0.000000   1.0   0.0   4.0   0.0   0.0   1.0   0.00      3\n",
       "2020-02-21          0.000661   2.0  -2.0   4.0   1.0   0.0   0.0   0.00      4\n",
       "...                      ...   ...   ...   ...   ...   ...   ...    ...    ...\n",
       "2021-06-02          5.628968  -2.0   5.0  40.0 -23.0 -30.0   7.0  50.45      2\n",
       "2021-06-03          6.348232  -3.0   6.0  37.0 -23.0 -29.0   7.0  50.56      3\n",
       "2021-06-04          5.611342  -5.0   2.0  44.0 -20.0 -28.0   6.0  50.75      4\n",
       "2021-06-05          4.628894  -6.0   5.0  74.0  -9.0  -8.0   0.0  50.91      5\n",
       "2021-06-06          1.795572  -2.0   3.0  60.0  -9.0 -10.0   0.0  51.08      6\n",
       "\n",
       "[476 rows x 9 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time series (non-case) features \n",
    "features_lag = ['rtrc', 'grph', 'prks', 'tran', 'work', 'resi', 'vac', 'dayow']\n",
    "# non-case features (mobility, vaccination, dayow) with lagging for previous 7 days\n",
    "df_case = pd.DataFrame(df.case_mil_percMax)\n",
    "dataset = df_case.join(df.loc[:,features_lag], on='date', how='left')\n",
    "# split into train and test\n",
    "n_test = 98 # (Days) 7 x 14, test model on the latest 14 weeks of data\n",
    "train, test = split_dataset(dataset.values, n_test) # splits dataset into train and test sets and reshape them to [samples, timesteps, features] (try train.shape)\n",
    "# evaluate model and get scores\n",
    "n_input = 28 # input four weeks of data \n",
    "n_out = 7 # forecast next 7 days\n",
    "score, scores, yhat, y = evaluate_model(train, test, n_input, n_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
