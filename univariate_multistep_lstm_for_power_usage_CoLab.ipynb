{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "univariate_multistep_lstm_for_power_usage_localver.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jup36/pyDatCode/blob/master/univariate_multistep_lstm_for_power_usage_CoLab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "er_fyTdhjCkS"
      },
      "source": [
        "## Univariate multi-step LSTM for the power usage dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8TUePak3vIu"
      },
      "source": [
        "#### Mount drive (in Colab)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8l4YQGu336wK"
      },
      "source": [
        "#from google.colab import drive (in Colab)\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkCEa_CT3n1p"
      },
      "source": [
        "#### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-scxGW0fhVd"
      },
      "source": [
        "from math import sqrt\n",
        "from numpy import split\n",
        "from numpy import array\n",
        "from pandas import read_csv\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyEdRtP05RQp"
      },
      "source": [
        "#### Read csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itymaFzF5T5X"
      },
      "source": [
        "colab_path = '/content/drive/My Drive/Colab_data/timeseries_dnn/' \n",
        "local_path = '/Volumes/GoogleDrive/My Drive/Colab_data/timeseries_dnn/'\n",
        "file_name = 'household_power_consumption_days.csv'\n",
        "# read\n",
        "dataset = read_csv(os.path.join(local_path,file_name), infer_datetime_format=True, parse_dates=['datetime'], index_col=['datetime'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xO9ci4nNi94V"
      },
      "source": [
        "#### Split a univariate dataset into train/test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lJPlKIJfkKO"
      },
      "source": [
        "def split_dataset(data):\n",
        "\t# split into standard weeks\n",
        "\ttrain, test = data[1:-328], data[-328:-6]\n",
        "\t# restructure into windows of weekly data\n",
        "\ttrain = array(split(train, len(train)/7))\n",
        "\ttest = array(split(test, len(test)/7))\n",
        "\treturn train, test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBmuSsVhj2ke"
      },
      "source": [
        "#### Evaluate one or more weekly forecasts against expected values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbQjh7cVjlP_"
      },
      "source": [
        "def evaluate_forecasts(actual, predicted):\n",
        "\tscores = list()\n",
        "\t# calculate an RMSE score for each day\n",
        "\tfor i in range(actual.shape[1]):\n",
        "\t\t# calculate mse\n",
        "\t\tmse = mean_squared_error(actual[:, i], predicted[:, i])\n",
        "\t\t# calculate rmse\n",
        "\t\trmse = sqrt(mse)\n",
        "\t\t# store\n",
        "\t\tscores.append(rmse)\n",
        "\t# calculate overall RMSE\n",
        "\ts = 0\n",
        "\tfor row in range(actual.shape[0]):\n",
        "\t\tfor col in range(actual.shape[1]):\n",
        "\t\t\ts += (actual[row, col] - predicted[row, col])**2\n",
        "\tscore = sqrt(s / (actual.shape[0] * actual.shape[1]))\n",
        "\treturn score, scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x69Jhda7kBO3"
      },
      "source": [
        "#### Summarize scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SM77p8fJjqIs"
      },
      "source": [
        "def summarize_scores(name, score, scores):\n",
        "\ts_scores = ', '.join(['%.1f' % s for s in scores])\n",
        "\tprint('%s: [%.3f] %s' % (name, score, s_scores))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGDcUkPAkHCJ"
      },
      "source": [
        "#### Convert history into inputs and outputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXcCZajCjtpW"
      },
      "source": [
        "def to_supervised(train, n_input, n_out=7):\n",
        "\t# flatten data\n",
        "\tdata = train.reshape((train.shape[0]*train.shape[1], train.shape[2]))\n",
        "\tX, y = list(), list()\n",
        "\tin_start = 0\n",
        "\t# step over the entire history one time step at a time\n",
        "\tfor _ in range(len(data)):\n",
        "\t\t# define the end of the input sequence\n",
        "\t\tin_end = in_start + n_input\n",
        "\t\tout_end = in_end + n_out\n",
        "\t\t# ensure we have enough data for this instance\n",
        "\t\tif out_end <= len(data):\n",
        "\t\t\tx_input = data[in_start:in_end, 0]\n",
        "\t\t\tx_input = x_input.reshape((len(x_input), 1))\n",
        "\t\t\tX.append(x_input)\n",
        "\t\t\ty.append(data[in_end:out_end, 0])\n",
        "\t\t# move along one time step\n",
        "\t\tin_start += 1\n",
        "\treturn array(X), array(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiRn5KgGkO2G"
      },
      "source": [
        "#### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3LwslbQjw_z"
      },
      "source": [
        "def build_model(train, n_input):\n",
        "\t# prepare data\n",
        "\ttrain_x, train_y = to_supervised(train, n_input)\n",
        "\t# define parameters\n",
        "\tverbose, epochs, batch_size = 0, 70, 16\n",
        "\tn_timesteps, n_features, n_outputs = train_x.shape[1], train_x.shape[2], train_y.shape[1]\n",
        "\t# define model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(LSTM(200, activation='relu', input_shape=(n_timesteps, n_features)))\n",
        "\tmodel.add(Dense(100, activation='relu'))\n",
        "\tmodel.add(Dense(n_outputs))\n",
        "\tmodel.compile(loss='mse', optimizer='adam')\n",
        "\t# fit network\n",
        "\tmodel.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
        "\treturn model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FD7UmLTXkpQF"
      },
      "source": [
        "#### Make a forecast"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySJr0Tb5ken9"
      },
      "source": [
        "def forecast(model, history, n_input):\n",
        "\t# flatten data\n",
        "\tdata = array(history)\n",
        "\tdata = data.reshape((data.shape[0]*data.shape[1], data.shape[2]))\n",
        "\t# retrieve last observations for input data\n",
        "\tinput_x = data[-n_input:, 0]\n",
        "\t# reshape into [1, n_input, 1]\n",
        "\tinput_x = input_x.reshape((1, len(input_x), 1))\n",
        "\t# forecast the next week\n",
        "\tyhat = model.predict(input_x, verbose=0)\n",
        "\t# we only want the vector forecast\n",
        "\tyhat = yhat[0]\n",
        "\treturn yhat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3M4FddCckzTL"
      },
      "source": [
        "#### Evaluate a single model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsLHHsRhkxO6"
      },
      "source": [
        "def evaluate_model(train, test, n_input):\n",
        "\t# fit model\n",
        "\tmodel = build_model(train, n_input)\n",
        "\t# history is a list of weekly data\n",
        "\thistory = [x for x in train]\n",
        "\t# walk-forward validation over each week\n",
        "\tpredictions = list()\n",
        "\tfor i in range(len(test)):\n",
        "\t\t# predict the week\n",
        "\t\tyhat_sequence = forecast(model, history, n_input)\n",
        "\t\t# store the predictions\n",
        "\t\tpredictions.append(yhat_sequence)\n",
        "\t\t# get real observation and add to history for predicting the next week\n",
        "\t\thistory.append(test[i, :])\n",
        "\t# evaluate predictions days for each week\n",
        "\tpredictions = array(predictions)\n",
        "\tscore, scores = evaluate_forecasts(test[:, :, 0], predictions)\n",
        "\treturn score, scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQ7GQQptk918"
      },
      "source": [
        "#### Main Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQCY25Q1k2_h"
      },
      "source": [
        "# split into train and test\n",
        "train, test = split_dataset(dataset.values) # splits dataset into train and test sets and reshape them to [samples, timesteps, features] (try train.shape)\n",
        "# evaluate model and get scores\n",
        "n_input = 7\n",
        "score, scores = evaluate_model(train, test, n_input)\n",
        "# summarize scores\n",
        "summarize_scores('lstm', score, scores)\n",
        "# plot scores\n",
        "days = ['sun', 'mon', 'tue', 'wed', 'thr', 'fri', 'sat']\n",
        "pyplot.plot(days, scores, marker='o', label='lstm')\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}